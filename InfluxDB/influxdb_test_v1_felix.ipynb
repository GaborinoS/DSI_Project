{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to influxdb on localhost\n",
    "#token whVmtiLViagPA8zCpz4-ItfX56GPhoGMUg4s9u-kx7fXmZTNcVE9xWNbLoTXB0c347vMG8vUxxIAKDPJdsFO6A==\n",
    "#org dsi\n",
    "#bucket s-p-500\n",
    "#bucket_id 5ab39a6efe08bcae\n",
    "#url http://localhost:8086\n",
    "\n",
    "from influxdb_client import InfluxDBClient, Point, WritePrecision\n",
    "import influxdb_client\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "\n",
    "# You can generate a Token from the \"Tokens Tab\" in the UI\n",
    "token = \"whVmtiLViagPA8zCpz4-ItfX56GPhoGMUg4s9u-kx7fXmZTNcVE9xWNbLoTXB0c347vMG8vUxxIAKDPJdsFO6A==\"\n",
    "org = \"dsi\"\n",
    "bucket = \"s-p-test\"\n",
    "client = InfluxDBClient(url=\"http://localhost:8086\", token=token)\n",
    "\n",
    "write_api = client.write_api(write_options=SYNCHRONOUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Point(\"my_measurement\").tag(\"location\", \"Prague\").field(\"temperature\", 25.3)\n",
    "write_api.write(bucket=bucket, org=org, record=p)\n",
    "\n",
    "#close connection\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write for 500 points\n",
    "\n",
    "for i in range(10):\n",
    "    p = Point(\"my_measurement\").tag(\"location\", \"Prague\").field(\"temperature\", 25.3)\n",
    "    write_api.write(bucket=bucket, org=org, record=p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Querying data\n",
    "query_api = client.query_api()\n",
    "query = 'from(bucket:\"s-p-test\")\\\n",
    "|> range(start: -10m)\\\n",
    "|> filter(fn:(r) => r._measurement == \"my_measurement\")\\\n",
    "|> filter(fn:(r) => r.location == \"Prague\")\\\n",
    "|> filter(fn:(r) => r._field == \"temperature\")'\n",
    "\n",
    "result = query_api.query(query, org=org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for table in result:\n",
    "  for record in table.records:\n",
    "    results.append((record.get_field(), record.get_value()))\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe wich memics a timeseries of a stock\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "# Create a dataframe with a column\n",
    "df = pd.DataFrame({'value': np.random.randn(1000)})\n",
    "# Add a column with a datetime index\n",
    "df['date'] = pd.date_range('1/1/2000', periods=1000)\n",
    "# Set the datetime column as the index\n",
    "df = df.set_index('date')\n",
    "# Create a column with a random walk\n",
    "df['value'] = df['value'].cumsum()\n",
    "\n",
    "\n",
    "print(df)\n",
    "#plot df\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(df.index, df['value'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "records = pd.DataFrame(\n",
    "    data=[\n",
    "        [\"0\", 25.3, 1657729063],\n",
    "    \t  [\"0\", 25.4, 1657729078],\n",
    "    \t  [\"0\", 25.2, 1657729093],\n",
    "    ],\n",
    "    columns=[\"core\", \"temp\", \"timestamp\"],\n",
    ")\n",
    "\n",
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with InfluxDBClient.from_config_file(\"config.toml\") as client:\n",
    "    with client.write_api() as writer:\n",
    "        writer.write(\n",
    "        \tbucket=\"testing\",\n",
    "        \trecord=records,\n",
    "        \tdata_frame_measurement_name=\"cpu\",\n",
    "        \tdata_frame_tag_columns=[\"core\"],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"whVmtiLViagPA8zCpz4-ItfX56GPhoGMUg4s9u-kx7fXmZTNcVE9xWNbLoTXB0c347vMG8vUxxIAKDPJdsFO6A==\"\n",
    "org = \"dsi\"\n",
    "bucket = \"s-p-test\"\n",
    "client = InfluxDBClient(url=\"http://localhost:8086\", token=token)\n",
    "\n",
    "write_api = client.write_api(write_options=SYNCHRONOUS)\n",
    "\n",
    "write_api.write(\n",
    "        org=\"dsi\",\n",
    "        bucket=\"testing\",\n",
    "        record=records,\n",
    "        data_frame_measurement_name=\"cpu\",\n",
    "        data_frame_tag_columns=[\"core\"]\n",
    "    )\n",
    "\n",
    "#close connection\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get json from https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=IBM&interval=5min&apikey=5LZM13OZQMZFPU92\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "url = \"https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=IBM&interval=5min&apikey=5LZM13OZQMZFPU92\"\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "#extract \"Meta Data\" and every \"Time Series (5min)\" entry\n",
    "meta_data = data[\"Meta Data\"]\n",
    "time_series = data[\"Time Series (5min)\"]\n",
    "\n",
    "#convert time_series to dataframe\n",
    "df = pd.DataFrame.from_dict(time_series, orient='index')\n",
    "\n",
    "# #print every row\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     print(row)\n",
    "\n",
    "#sort dataframe by index\n",
    "df = df.sort_index()\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Package\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "#Data viz\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "#Data Source\n",
    "import yfinance as yf\n",
    "\n",
    "#Interval required 1 minute\n",
    "data = yf.download(tickers='IBM', period='1d', interval='1m')\n",
    "\n",
    "#declare figure\n",
    "fig = go.Figure()\n",
    "\n",
    "#Candlestick\n",
    "fig.add_trace(go.Candlestick(x=data.index,\n",
    "                open=data['Open'],\n",
    "                high=data['High'],\n",
    "                low=data['Low'],\n",
    "                close=data['Close'], name = 'market data'))\n",
    "\n",
    "# Add titles\n",
    "fig.update_layout(\n",
    "    title='Uber live share price evolution',\n",
    "    yaxis_title='Stock Price (USD per Shares)')\n",
    "\n",
    "# X-Axes\n",
    "fig.update_xaxes(\n",
    "    rangeslider_visible=True,\n",
    "    rangeselector=dict(\n",
    "        buttons=list([\n",
    "            dict(count=15, label=\"15m\", step=\"minute\", stepmode=\"backward\"),\n",
    "            dict(count=45, label=\"45m\", step=\"minute\", stepmode=\"backward\"),\n",
    "            dict(count=1, label=\"HTD\", step=\"hour\", stepmode=\"todate\"),\n",
    "            dict(count=3, label=\"3h\", step=\"hour\", stepmode=\"backward\"),\n",
    "            dict(step=\"all\")\n",
    "        ])\n",
    "    )\n",
    ")\n",
    "\n",
    "#Show\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = yf.download(tickers='IBM', period='1d', interval='1m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dataframe to json\n",
    "a = df.to_json(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_json(a, orient='index')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import influxdb_client\n",
    "from influxdb import DataFrameClient\n",
    "from influxdb_client import InfluxDBClient, Point\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "from influxdb_client.client.write_api import ASYNCHRONOUS\n",
    "\n",
    "#InfluxDB connection\n",
    "bucket = \"DSI_test\"\n",
    "#token =\"yxk8_Or5qHZJxrhJE3SkAnTQSViQCsmrUoR0xPZd_0scy1T8FTuL1cKSTDKh1ft8Bqs3Zbt7Rwkys-FzajIVFQ==\"\n",
    "token =\"GMbnHWGhM9p9t9mIjbc1I5KlWir8LJxBDkpMF0SiOa56f1nvLepCEN7iI_5-sR80FA8CvLmf_mHcy8Gc5XYwvA==\"\n",
    "org=\"dsi\"\n",
    "client = InfluxDBClient(url=\"http://localhost:8086\", token=token, org=org)\n",
    "#client = InfluxDBClient(url=\"http://172.19.0.2:8086\", token=token, org=org)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = yf.download(tickers='IBM', period='1d', interval='1m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with client.write_api(write_options=SYNCHRONOUS) as writer:\n",
    "    writer.write(\n",
    "        bucket=bucket,\n",
    "        record=data,\n",
    "        data_frame_measurement_name=\"key2\",\n",
    "        #data_frame_tag_columns=[\"symbol\"],\n",
    "        data_frame_field_columns=[\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = yf.download(tickers=\"IBM\", period='1d', interval='1m').to_json(orient = \"index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_json(data)\u001b[39m.\u001b[39mT\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(data).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set indx name of dataframe to Datetime\n",
    "df.index.name = 'Datetime'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
